{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15f3313a-83d2-440d-85f9-2de15333e57e",
   "metadata": {},
   "source": [
    "# Streamlined Model Builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6428fe39-6079-494f-984d-5d33e0eeed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required packages\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, SeparableConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a0e9ec-4d11-4e70-989d-aed5a317da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data directory relative path (expecting subdirectories of classes)\n",
    "os.chdir(\"/Users/andrew/Documents/Research/BiodivInformatics/AI-carabids/\")\n",
    "data_dir = 'JORN'\n",
    "#find names of classes\n",
    "classes=os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aca92e1-e53d-467e-bfde-c4bc74874d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 files belonging to 14 classes.\n",
      "Using 178 files for training.\n",
      "Using 76 files for validation.\n"
     ]
    }
   ],
   "source": [
    "#Read in data\n",
    "train, val = tf.keras.utils.image_dataset_from_directory(data_dir, image_size=(400, 600), validation_split=0.3, subset=\"both\", seed=452198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a0ce25c-6ebd-4b9d-b45b-8f072b0a6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "train_scaled = train.map(lambda x,y: (x/255, y))\n",
    "val_scaled = val.map(lambda x,y: (x/255, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0565bb6a-0335-4ac3-be53-b59e5fe64bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(14, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88252c7b-1013-4944-ad79-7439d033d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 200, 300, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 100, 150, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 50, 75, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 25, 38, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 12, 19, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 256)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 14)                7182      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 509582 (1.94 MB)\n",
      "Trainable params: 509582 (1.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile model and set up logs and callbacks\n",
    "model.compile('adam', loss=tf.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e152d477-4e51-4e0d-b30a-13d69cdb6a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 14s 1s/step - loss: 0.5627 - accuracy: 0.8034 - val_loss: 0.7389 - val_accuracy: 0.6842\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 14s 1s/step - loss: 0.5469 - accuracy: 0.7978 - val_loss: 0.5900 - val_accuracy: 0.8158\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 13s 1s/step - loss: 0.5776 - accuracy: 0.7640 - val_loss: 0.9234 - val_accuracy: 0.6316\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 14s 1s/step - loss: 0.6107 - accuracy: 0.7472 - val_loss: 0.5007 - val_accuracy: 0.8421\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 13s 1s/step - loss: 0.5249 - accuracy: 0.8034 - val_loss: 0.6455 - val_accuracy: 0.7237\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 13s 1s/step - loss: 0.5189 - accuracy: 0.8034 - val_loss: 0.4963 - val_accuracy: 0.8289\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 14s 1s/step - loss: 0.4514 - accuracy: 0.8090 - val_loss: 0.5598 - val_accuracy: 0.8026\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 13s 1s/step - loss: 0.4295 - accuracy: 0.8427 - val_loss: 0.8793 - val_accuracy: 0.7237\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 14s 1s/step - loss: 0.9186 - accuracy: 0.6854 - val_loss: 1.0647 - val_accuracy: 0.6053\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 13s 1s/step - loss: 1.0560 - accuracy: 0.5899 - val_loss: 0.8568 - val_accuracy: 0.6316\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 13s 1s/step - loss: 0.7555 - accuracy: 0.6966 - val_loss: 0.7139 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.7584Restoring model weights from the end of the best epoch: 6.\n",
      "6/6 [==============================] - 13s 1s/step - loss: 0.5969 - accuracy: 0.7584 - val_loss: 0.5650 - val_accuracy: 0.8158\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "hist = model.fit(train_scaled, epochs=100, validation_data=val_scaled, callbacks=[tensorboard_callback, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff62e8-c9ed-4164-bd6d-9f67fd666e8f",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- padding='same' is important, bumps up how fast the models starts to increase, and jumps the val_accuracy by 10% right away\n",
    "- average global pooling is a little faster\n",
    "- number of filters increases computation time. Might not have a huge response to accuracy of 12-sp dataset?\n",
    "- fewer conv2d layers make epochs faster but require more epochs to 'catch' onto higher accuracy?\n",
    "- Not sure about removing one of the pooling layers or not. Trying out slightly increasing the filters for some of the layers to see if the val accuracy goes up faster - so far seems like maybe\n",
    "- removing some layers is definitely the way to go. increasing filters seems to slightly help the model 'catch' but it doesn't seem to make a huge difference on val accuracy in this dataset\n",
    "- the second to last dense layer seems to work fine at 256 or 512 ... not a major difference in final acuracy or speed to get there, just reduces the model size\n",
    "- Changing strides from 2 down to 1 creates a 5-fold increase in epoch time (for 3x3 kernal size) - if anything it performed worse over 100 epochs\n",
    "- increasing second to last dense layer makes hte model train faster (fewer epochs) - unsure of convergence differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c51fc8d7-2072-45af-8e51-36a702c047b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/JORN-14.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/JORN-14.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join('models','JORN-14.tf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c24cfa-a3b6-42aa-8118-0beba7bfce12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CALPER2',\n",
       " 'CHLSER',\n",
       " 'CHLTOM',\n",
       " 'CICPUN',\n",
       " 'CYMPUN2',\n",
       " 'DISROB',\n",
       " 'EURGRO',\n",
       " 'HAROBL',\n",
       " 'HARPEN',\n",
       " 'HELFER',\n",
       " 'JUNLEM',\n",
       " 'PASOBS',\n",
       " 'SELPLA',\n",
       " 'TETPAL']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282abec9-6a98-4074-933a-f863d6024a06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## JORN-12 Previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0e426-8db5-42fa-9f61-64004ec16c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model finally saved after 300 epochs, 90-95% val_accuracy\n",
    "\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2364d3d-25de-47d1-8331-2af95d703fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast epochs, 300 on M2 got up to low 90%'s\n",
    "\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69742cb-b85b-4435-8091-da6863aedbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast epochs (10s on M2) ~85% but between 80 and 90, never fully converged\n",
    "\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(728, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1fa61-cb05-4fac-baa6-ea0f7d46fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High 80's near 90%, 10s on M2\n",
    "\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(728, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1284b-8486-414f-be4c-a7da18de3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast epochs (15-16sec) took about 200 epochs - 85-90%, training and val did not ever converge to 100%\n",
    "\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd83861d-afc9-45fe-85b6-2187352c6fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fast epochs (15s) but took 250 epochs - 80-85%\n",
    "\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "#model.add(Conv2D(16, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(Conv2D(32, (3,3), 1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), 2, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383569c-6375-4e0b-9f37-a3cc0b9df43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fairly fast ~65-70%\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 2, activation='relu', input_shape=(400,600,3), padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(512, (3,3), 2, activation='relu', padding='same'))\n",
    "#model.add(MaxPooling2D())\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(1028, (3,3), 2, activation='relu'))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dropout(0.8))\n",
    "#number of final possibilities is n-1\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce718895-3b6f-4ee6-957e-8f0c6ec1ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original CNN from 5sp test - ~40%\n",
    "#establish a model - can do rest inside first command or use the add method\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, (5,5), 1, activation='relu', input_shape=(400,600,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (5,5), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (5,5), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#number of final possibilities\n",
    "model.add(Dense(12, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246e7ec3-bdcb-4f10-a5e4-3ea2aa39a6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fff7bc-253a-4a3d-a24a-e9886434426c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63cc753-7f59-4062-bad1-8df43e773777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ee0b3-1d37-48f0-b4e7-b3d7ad093f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e6d95-8a53-4865-b950-b665b7c21839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9f99d16-2fa0-4d94-a43e-5895dfe9a9cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Xception clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c143fcbe-c185-42ca-a6f8-e88d362e86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copied from https://keras.io/examples/vision/image_classification_from_scratch/\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Entry block\n",
    "    #x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=(400, 600) + (3,), num_classes=12)\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f3430-e477-49e6-827c-62971dfd61cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7/7 [==============================] - 1284s 169s/step - loss: 1.8648 - accuracy: 0.2917 - val_loss: 2.4880 - val_accuracy: 0.0926\n",
      "Epoch 2/25\n",
      "7/7 [==============================] - 2492s 386s/step - loss: 1.4134 - accuracy: 0.4444 - val_loss: 2.5003 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 03:29:06.006285: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 63 of 256\n",
      "2023-08-25 03:29:16.086519: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 134 of 256\n",
      "2023-08-25 03:29:26.295964: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 203 of 256\n",
      "2023-08-25 03:29:27.572230: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1502s 203s/step - loss: 1.2119 - accuracy: 0.4954 - val_loss: 2.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 03:54:08.236416: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 100 of 256\n",
      "2023-08-25 03:54:18.354160: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 203 of 256\n",
      "2023-08-25 03:54:19.161916: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1376s 189s/step - loss: 0.9261 - accuracy: 0.6111 - val_loss: 2.5246 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 04:17:04.300161: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 100 of 256\n",
      "2023-08-25 04:17:14.443692: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 208 of 256\n",
      "2023-08-25 04:17:14.925496: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1372s 189s/step - loss: 0.8837 - accuracy: 0.6991 - val_loss: 2.5443 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 04:39:56.798043: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 100 of 256\n",
      "2023-08-25 04:40:06.650287: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 203 of 256\n",
      "2023-08-25 04:40:07.538098: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1792s 261s/step - loss: 0.9289 - accuracy: 0.6713 - val_loss: 2.5728 - val_accuracy: 0.0556\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 05:09:49.027251: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 66 of 256\n",
      "2023-08-25 05:09:59.086182: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 138 of 256\n",
      "2023-08-25 05:10:09.031479: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 216 of 256\n",
      "2023-08-25 05:10:09.031543: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2110s 300s/step - loss: 0.7559 - accuracy: 0.7500 - val_loss: 2.5980 - val_accuracy: 0.0556\n",
      "Epoch 8/25\n",
      "7/7 [==============================] - 2040s 311s/step - loss: 0.7099 - accuracy: 0.7731 - val_loss: 2.6315 - val_accuracy: 0.0556\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 06:34:31.370116: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 53 of 256\n",
      "2023-08-25 06:34:31.452979: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 54 of 256\n",
      "2023-08-25 06:34:31.495947: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 55 of 256\n",
      "2023-08-25 06:34:31.496006: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 56 of 256\n",
      "2023-08-25 06:34:31.651546: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 57 of 256\n",
      "2023-08-25 06:34:31.651560: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 58 of 256\n",
      "2023-08-25 06:34:31.651562: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 59 of 256\n",
      "2023-08-25 06:34:31.651564: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 60 of 256\n",
      "2023-08-25 06:34:31.707229: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 61 of 256\n",
      "2023-08-25 06:34:31.755495: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 62 of 256\n",
      "2023-08-25 06:34:31.995297: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 63 of 256\n",
      "2023-08-25 06:34:31.995308: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 64 of 256\n",
      "2023-08-25 06:34:31.995312: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 65 of 256\n",
      "2023-08-25 06:34:32.126227: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 66 of 256\n",
      "2023-08-25 06:34:32.126769: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 67 of 256\n",
      "2023-08-25 06:34:32.126778: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 68 of 256\n",
      "2023-08-25 06:34:32.126783: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 69 of 256\n",
      "2023-08-25 06:34:32.134376: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 70 of 256\n",
      "2023-08-25 06:34:32.231593: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 71 of 256\n",
      "2023-08-25 06:34:32.425395: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 72 of 256\n",
      "2023-08-25 06:34:32.425417: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 73 of 256\n",
      "2023-08-25 06:34:32.427088: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 74 of 256\n",
      "2023-08-25 06:34:32.469966: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 75 of 256\n",
      "2023-08-25 06:34:32.469977: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 76 of 256\n",
      "2023-08-25 06:34:32.469979: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 77 of 256\n",
      "2023-08-25 06:34:32.504625: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 78 of 256\n",
      "2023-08-25 06:34:32.504655: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 79 of 256\n",
      "2023-08-25 06:34:32.556363: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 80 of 256\n",
      "2023-08-25 06:34:32.773451: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 81 of 256\n",
      "2023-08-25 06:34:32.773554: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 82 of 256\n",
      "2023-08-25 06:34:32.773689: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 83 of 256\n",
      "2023-08-25 06:34:32.773695: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 84 of 256\n",
      "2023-08-25 06:34:32.784684: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 85 of 256\n",
      "2023-08-25 06:34:32.792774: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 86 of 256\n",
      "2023-08-25 06:34:32.795135: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 87 of 256\n",
      "2023-08-25 06:34:32.795143: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 88 of 256\n",
      "2023-08-25 06:34:32.869596: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 89 of 256\n",
      "2023-08-25 06:34:33.018081: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 90 of 256\n",
      "2023-08-25 06:34:33.018097: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 91 of 256\n",
      "2023-08-25 06:34:33.032343: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 92 of 256\n",
      "2023-08-25 06:34:33.112237: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 93 of 256\n",
      "2023-08-25 06:34:33.112258: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 94 of 256\n",
      "2023-08-25 06:34:33.112270: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 95 of 256\n",
      "2023-08-25 06:34:33.112275: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 96 of 256\n",
      "2023-08-25 06:34:33.112281: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 97 of 256\n",
      "2023-08-25 06:34:33.319473: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 98 of 256\n",
      "2023-08-25 06:34:33.319486: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 99 of 256\n",
      "2023-08-25 06:34:33.395492: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 100 of 256\n",
      "2023-08-25 06:34:33.395512: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 101 of 256\n",
      "2023-08-25 06:34:33.524185: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 102 of 256\n",
      "2023-08-25 06:34:33.524205: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 103 of 256\n",
      "2023-08-25 06:34:33.524210: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 104 of 256\n",
      "2023-08-25 06:34:33.524214: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 105 of 256\n",
      "2023-08-25 06:34:33.524218: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 106 of 256\n",
      "2023-08-25 06:34:33.563685: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 107 of 256\n",
      "2023-08-25 06:34:33.564867: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 108 of 256\n",
      "2023-08-25 06:34:33.753230: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 109 of 256\n",
      "2023-08-25 06:34:33.753252: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 110 of 256\n",
      "2023-08-25 06:34:33.886312: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 111 of 256\n",
      "2023-08-25 06:34:33.886326: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 112 of 256\n",
      "2023-08-25 06:34:33.886329: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 113 of 256\n",
      "2023-08-25 06:34:33.886373: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 114 of 256\n",
      "2023-08-25 06:34:33.886388: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 115 of 256\n",
      "2023-08-25 06:34:33.886408: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 116 of 256\n",
      "2023-08-25 06:34:33.947111: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 117 of 256\n",
      "2023-08-25 06:34:33.967447: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 118 of 256\n",
      "2023-08-25 06:34:34.099253: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 119 of 256\n",
      "2023-08-25 06:34:34.129000: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 120 of 256\n",
      "2023-08-25 06:34:34.243657: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 121 of 256\n",
      "2023-08-25 06:34:34.243684: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 122 of 256\n",
      "2023-08-25 06:34:34.243689: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 123 of 256\n",
      "2023-08-25 06:34:34.243693: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 124 of 256\n",
      "2023-08-25 06:34:34.243697: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 125 of 256\n",
      "2023-08-25 06:34:34.255137: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 126 of 256\n",
      "2023-08-25 06:34:34.309921: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 127 of 256\n",
      "2023-08-25 06:34:34.365506: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 128 of 256\n",
      "2023-08-25 06:34:34.444439: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 129 of 256\n",
      "2023-08-25 06:34:34.477543: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 130 of 256\n",
      "2023-08-25 06:34:34.477552: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 131 of 256\n",
      "2023-08-25 06:34:34.477554: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 132 of 256\n",
      "2023-08-25 06:34:34.486637: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 133 of 256\n",
      "2023-08-25 06:34:34.493150: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 134 of 256\n",
      "2023-08-25 06:34:34.671455: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 135 of 256\n",
      "2023-08-25 06:34:34.671467: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 136 of 256\n",
      "2023-08-25 06:34:34.693798: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 137 of 256\n",
      "2023-08-25 06:34:34.789749: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 138 of 256\n",
      "2023-08-25 06:34:34.789762: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 139 of 256\n",
      "2023-08-25 06:34:34.789906: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 140 of 256\n",
      "2023-08-25 06:34:34.790012: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 141 of 256\n",
      "2023-08-25 06:34:34.790650: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 142 of 256\n",
      "2023-08-25 06:34:34.835316: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 143 of 256\n",
      "2023-08-25 06:34:34.889970: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 144 of 256\n",
      "2023-08-25 06:34:34.915644: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 145 of 256\n",
      "2023-08-25 06:34:35.043306: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:422] Filling up shuffle buffer (this may take a while): 146 of 256\n",
      "2023-08-25 06:34:37.231149: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2226s 186s/step - loss: 0.6169 - accuracy: 0.7963 - val_loss: 2.6538 - val_accuracy: 0.0556\n",
      "Epoch 10/25\n",
      "7/7 [==============================] - 985s 140s/step - loss: 0.5971 - accuracy: 0.8102 - val_loss: 2.6986 - val_accuracy: 0.0556\n",
      "Epoch 11/25\n",
      "7/7 [==============================] - 975s 140s/step - loss: 0.5538 - accuracy: 0.7917 - val_loss: 2.7360 - val_accuracy: 0.0556\n",
      "Epoch 12/25\n",
      "7/7 [==============================] - 1183s 167s/step - loss: 0.4286 - accuracy: 0.8981 - val_loss: 2.7777 - val_accuracy: 0.0556\n",
      "Epoch 13/25\n",
      "7/7 [==============================] - 1175s 164s/step - loss: 0.3670 - accuracy: 0.8935 - val_loss: 2.8256 - val_accuracy: 0.0556\n",
      "Epoch 14/25\n",
      "4/7 [================>.............] - ETA: 9:25 - loss: 0.2628 - accuracy: 0.9609 "
     ]
    }
   ],
   "source": [
    "# run model\n",
    "epochs = 25\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.legacy.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    train_scaled,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=val_scaled,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127414e8-3955-4ac6-a359-f8aa52f8c453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NF-PASCAL',\n",
       " '.DS_Store',\n",
       " 'CHLSER',\n",
       " 'NF-PASELO',\n",
       " 'JUNLEM',\n",
       " 'NF-OMUDEJ',\n",
       " 'CALPER2',\n",
       " 'NF-PTELAM',\n",
       " 'CYMPUN2',\n",
       " 'CICPUN',\n",
       " 'NF-SCASUB2',\n",
       " 'DISROB',\n",
       " 'CHLTOM']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b415280-2c4f-44bd-811f-d51226921da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
